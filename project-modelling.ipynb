{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e626aa51",
   "metadata": {},
   "source": [
    "# Big Collection of Songs & Audio Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a616306",
   "metadata": {},
   "source": [
    "### Converted to Markdown to prevent from running, the output dataset is saved as a .csv file in the working directory\n",
    "#### See output from previous version with commit message containing \"songs collected\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4ce12f",
   "metadata": {},
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "secrets_file = open(\"spotifyclientsecret.txt\",\"r\")\n",
    "string = secrets_file.read()\n",
    "secrets_dict={}\n",
    "for line in string.split('\\n'):\n",
    "    if len(line) > 0:\n",
    "        #print(line.split(':'))\n",
    "        secrets_dict[line.split(':')[0]]=line.split(':')[1].strip()\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=secrets_dict['clientid'],\n",
    "                                                           client_secret=secrets_dict['clientsecret'])) # establish connection to Spotify Web api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db27924",
   "metadata": {},
   "source": [
    "from random import randint\n",
    "from time import sleep\n",
    "\n",
    "def get_playlist_tracks(playlist_id):\n",
    "    results = sp.user_playlist_tracks(\"spotify\",playlist_id)\n",
    "    tracks = results['items']\n",
    "    while results['next']!=None:\n",
    "        results = sp.next(results)\n",
    "        tracks = tracks + results['items']\n",
    "        sleep(randint(1,500)/1000) # respectful nap\n",
    "    return tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1620674",
   "metadata": {},
   "source": [
    "all_tracks = get_playlist_tracks(\"6yPiKpy7evrwvZodByKvM9\")\n",
    "len(all_tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8211635f",
   "metadata": {},
   "source": [
    "tracks = json_normalize(all_tracks)\n",
    "artists_df = pd.DataFrame(columns=['href', 'id', 'name', 'type', 'uri', 'external_urls.spotify','song_id', 'song_name', 'popularity' ])\n",
    "for i in tracks.index:\n",
    "    artists_for_song = json_normalize(tracks.iloc[i]['track.artists'])\n",
    "    artists_for_song['song_id']    = tracks.iloc[i]['track.id']         # we want to keep song_id, it is the sae for all artists\n",
    "    artists_for_song['song_name']  = tracks.iloc[i]['track.name']       # we want to keep song_name, it is the sae for all artists\n",
    "    artists_for_song['popularity'] = tracks.iloc[i]['track.popularity'] # same for popularity   \n",
    "    artists_df = pd.concat([artists_df, artists_for_song], axis=0)\n",
    "\n",
    "df_final = artists_df[['song_name', 'name', 'song_id', 'popularity']].reset_index(drop=True)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1710ff",
   "metadata": {},
   "source": [
    "#Audio feature:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c02bf59",
   "metadata": {},
   "source": [
    "df_final['song_id'].isnull().sum() #??????"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d836f1fa",
   "metadata": {},
   "source": [
    "df_final.dropna(inplace=True) # can't be bothered to investigate, just drop na\n",
    "\n",
    "chunks = [(i, i+100) for i in range(0, len(df_final), 100)]\n",
    "\n",
    "audio_features_list = []\n",
    "for chunk in chunks:\n",
    "    id_list100 = df_final['song_id'][chunk[0]:chunk[1]]\n",
    "    audio_features_list = audio_features_list + sp.audio_features(id_list100)\n",
    "    sleep(randint(1,1000)/1000)\n",
    "len(audio_features_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5fc171",
   "metadata": {},
   "source": [
    "audio_features_df = pd.DataFrame(audio_features_list)\n",
    "audio_features_df.drop_duplicates(inplace=True)\n",
    "\n",
    "df_w_audio_ft = pd.merge(left=df_final,\n",
    "                        right=audio_features_df,\n",
    "                        how='inner',\n",
    "                        left_on='song_id',\n",
    "                        right_on='id')\n",
    "df_w_audio_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacbb19c",
   "metadata": {},
   "source": [
    "#save to csv:\n",
    "df_w_audio_ft.to_csv('curated_song_and_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4178cfe0",
   "metadata": {},
   "source": [
    "# Pull features of input song & clustering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "015544e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('curated_song_and_features.csv')\n",
    "data.drop(['Unnamed: 0'],axis=1, inplace=True)\n",
    "X = data[['danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo']]\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler().fit(X)\n",
    "X_prep = scaler.transform(X)\n",
    "#----------------------------------------------------------Selecting K---------------------------------------------------------------\n",
    "# import numpy as np\n",
    "# K = range(2, 20)\n",
    "# inertia = []\n",
    "\n",
    "# for k in K:\n",
    "#     kmeans = KMeans(n_clusters=k,\n",
    "#                 init=\"random\",\n",
    "#                 n_init= 100,  # try with 1, 4, 8, 20, 30, 100...\n",
    "#                 max_iter=100,\n",
    "#                 tol=0,\n",
    "#                 random_state=42)\n",
    "#     kmeans.fit(X_prep)\n",
    "#     inertia.append(kmeans.inertia_)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "# plt.figure(figsize=(16,8))\n",
    "# plt.plot(K, inertia, 'bx-')\n",
    "# plt.xlabel('k')\n",
    "# plt.ylabel('inertia')\n",
    "# plt.xticks(np.arange(min(K), max(K)+1, 1.0))\n",
    "# plt.title('Elbow Method showing the optimal k')\n",
    "\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# K = range(2, 20)\n",
    "# silhouette = []\n",
    "\n",
    "# for k in K:\n",
    "#     kmeans = KMeans(n_clusters=k,\n",
    "#                 init=\"random\",\n",
    "#                 n_init= 100,  #\n",
    "#                 max_iter=100,\n",
    "#                 tol=0,\n",
    "#                 random_state=42)\n",
    "#     kmeans.fit(X_prep)\n",
    "#     silhouette.append(silhouette_score(X_prep, kmeans.predict(X_prep)))\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(16,8))\n",
    "# plt.plot(K, silhouette, 'bx-')\n",
    "# plt.xlabel('k')\n",
    "# plt.ylabel('silhouette score')\n",
    "# plt.xticks(np.arange(min(K), max(K)+1, 1.0))\n",
    "# plt.title('Slhouette score showing the optimal k')\n",
    "\n",
    "#---------------------------------------------------------Clustering model-----------------------------------------------------------\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# I chose 7 for K\n",
    "kmeans = KMeans(n_clusters=20, init=\"random\",\n",
    "                n_init= 100,\n",
    "                max_iter=100,\n",
    "                tol=0,\n",
    "                random_state=42) \n",
    "kmeans.fit(X_prep)\n",
    "\n",
    "# Predicting / assigning the clusters:\n",
    "clusters = kmeans.predict(X_prep)\n",
    "\n",
    "# Check the size of the clusters\n",
    "# pd.Series(clusters).value_counts()\n",
    "\n",
    "# add to the big dataframe of songs and features\n",
    "data['cluster'] = clusters\n",
    "\n",
    "# another dataframe just for ease of use\n",
    "songs_server = data[['song_name','name','cluster']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d37c575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('kmeans_model_20clusters.pkl', 'wb') as file: #save model to this name\n",
    "    pickle.dump(kmeans, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3c836af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler_minmax.pkl', 'wb') as file: #save scaler to this name\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83ba99de",
   "metadata": {},
   "outputs": [],
   "source": [
    "servo_library = data[['song_name','name','song_id','cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a45f0754",
   "metadata": {},
   "outputs": [],
   "source": [
    "servo_library.to_csv('our_library.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
